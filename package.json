{
	"name": "oai-compatible-copilot",
	"publisher": "johnny-zhao",
	"displayName": "OAI Compatible Provider for Copilot",
	"description": "An extension that integrates Openai Compatible Inference Providers into GitHub Copilot Chat",
	"icon": "assets/logo.png",
	"keywords": [
		"ai",
		"chat",
		"copilot",
		"github-copilot",
		"language-model"
	],
	"repository": {
		"type": "git",
		"url": "https://github.com/JohnnyZ93/oai-compatible-copilot"
	},
	"version": "0.1.5-beta-3",
	"engines": {
		"vscode": "^1.104.0"
	},
	"extensionDependencies": [
		"github.copilot-chat"
	],
	"categories": [
		"AI",
		"Chat"
	],
	"badges": [
		{
			"url": "https://img.shields.io/github/stars/JohnnyZ93/oai-compatible-copilot?style=social",
			"description": "Star oai-compatible-copilot on Github",
			"href": "https://github.com/JohnnyZ93/oai-compatible-copilot"
		}
	],
	"bugs": {
		"url": "https://github.com/JohnnyZ93/oai-compatible-copilot/issues"
	},
	"license": "MIT",
	"enabledApiProposals": [
		"chatProvider",
		"languageModelDataPart",
		"languageModelThinkingPart"
	],
	"contributes": {
		"languageModelChatProviders": [
			{
				"vendor": "oaicopilot",
				"displayName": "OAI Compatible",
				"managementCommand": "oaicopilot.setApikey"
			}
		],
		"commands": [
			{
				"command": "oaicopilot.setApikey",
				"title": "OAICopilot: Set OAI Compatible Apikey"
			},
			{
				"command": "oaicopilot.setProviderApikey",
				"title": "OAICopilot: Set OAI Compatible Multi-Provider Apikey"
			}
		],
		"configuration": {
			"title": "OAI Compatible Copilot",
			"properties": {
				"oaicopilot.baseUrl": {
					"type": "string",
					"default": "https://router.huggingface.co/v1",
					"description": "The base URL for the Openai Compatible Inference API. Default value is Hugging Face."
				},
				"oaicopilot.proxy": {
					"type": "string",
					"default": "",
					"description": "Proxy URL (e.g. http://127.0.0.1:8890) to use for requests. Leave empty to disable."
				},
				"oaicopilot.models": {
					"type": "array",
					"default": [],
					"items": {
						"type": "object",
						"properties": {
							"id": {
								"type": "string",
								"description": "Model ID (e.g., 'glm-4.6')."
							},
							"displayName": {
								"type": "string",
								"description": "(Optional) Display name for the model that will be shown in the Copilot interface. If not provided, will be generated automatically."
							},
							"configId": {
								"type": "string",
								"description": "(Optional) Configuration ID for this model. Allows defining the same model with different settings (e.g. 'glm-4.6::thinking', 'glm-4.6::no-thinking')."
							},
							"owned_by": {
								"type": "string",
								"description": "Model provider (e.g., 'zai', 'openai')."
							},
							"family": {
								"type": "string",
								"description": "Model family (e.g., 'gpt-4', 'claude-3', 'gemini'). Enables model-specific optimizations and behaviors. Defaults to 'oai-compatible' if not specified."
							},
							"baseUrl": {
								"type": "string",
								"description": "Base URL for the model provider. If not provided, the global oaicopilot.baseUrl will be used."
							},
							"context_length": {
								"type": "number",
								"default": 128000,
								"minimum": 1000,
								"maximum": 10000000,
								"description": "Model support context length. Default is 128000."
							},
							"vision": {
								"type": "boolean",
								"default": false,
								"description": "Model support vision. Default is false."
							},
							"max_tokens": {
								"type": "number",
								"default": 4096,
								"minimum": 1,
								"maximum": 10000000,
								"description": "Maximum number of tokens to generate (range: [1, context_length)). Default is 4096."
							},
							"max_completion_tokens": {
								"type": "number",
								"default": 4096,
								"minimum": 1,
								"maximum": 10000000,
								"description": "Maximum number of tokens to generate (OpenAI new standard parameter)."
							},
							"reasoning_effort": {
								"type": "string",
								"default": "medium",
								"enum": [
									"high",
									"medium",
									"low",
									"minimal"
								],
								"description": "Reasoning effort level (OpenAI reasoning configuration)"
							},
							"thinking": {
								"type": "object",
								"description": "Thinking configuration for Zai provider",
								"properties": {
									"type": {
										"type": "string",
										"enum": [
											"enabled",
											"disabled"
										],
										"description": "Set to 'enabled' to enable thinking, 'disabled' to disable thinking"
									}
								}
							},
							"enable_thinking": {
								"type": "boolean",
								"default": false,
								"description": "Switches between thinking and non-thinking modes. Not required."
							},
							"thinking_budget": {
								"type": "number",
								"default": 128,
								"minimum": 128,
								"maximum": 10000000,
								"description": "Maximum number of tokens for chain-of-thought output. Not required."
							},
							"temperature": {
								"type": "number",
								"default": 0,
								"minimum": 0,
								"maximum": 2,
								"description": "Sampling temperature (range: [0, 2]). Lower values make output more deterministic, higher values make it more creative. Default is 0."
							},
							"top_p": {
								"type": "number",
								"default": 1,
								"minimum": 0,
								"maximum": 1,
								"description": "Top-p sampling value (range: (0, 1]). Default is 1."
							},
							"top_k": {
								"type": "number",
								"default": 50,
								"minimum": 1,
								"description": "Top-k sampling value (range: [1, Infinity)). Not required."
							},
							"min_p": {
								"type": "number",
								"default": 0,
								"minimum": 0,
								"maximum": 1,
								"description": "Minimum probability threshold (range: [0, 1]). Not required."
							},
							"frequency_penalty": {
								"type": "number",
								"default": 0,
								"minimum": -2,
								"maximum": 2,
								"description": "Frequency penalty (range: [-2, 2]). Not required."
							},
							"presence_penalty": {
								"type": "number",
								"default": 0,
								"minimum": -2,
								"maximum": 2,
								"description": "Presence penalty (range: [-2, 2]). Not required."
							},
							"repetition_penalty": {
								"type": "number",
								"default": 0,
								"minimum": 0,
								"maximum": 2,
								"description": "Repetition penalty (range: (0, 2]). Not required."
							},
							"reasoning": {
								"type": "object",
								"default": {
									"effort": "medium"
								},
								"properties": {
									"effort": {
										"type": "string",
										"default": "medium",
										"enum": [
											"high",
											"medium",
											"low",
											"minimal",
											"auto"
										],
										"description": "Reasoning effort level for OpenRouter/xAI (high, medium, low, minimal, auto)"
									},
									"exclude": {
										"type": "boolean",
										"default": false,
										"description": "Exclude reasoning tokens from the final response"
									},
									"max_tokens": {
										"type": "number",
										"default": 2000,
										"minimum": 1,
										"description": "Specific token limit for reasoning (Anthropic-style, alternative to effort)"
									},
									"enabled": {
										"type": "boolean",
										"default": true,
										"description": "Enable reasoning (inferred from effort or max_tokens if not specified)"
									}
								},
								"description": "Reasoning configuration for OpenRouter-compatible providers"
							},
							"extra": {
								"type": "object",
								"description": "Extra request parameters that will be used in /chat/completions."
							},
							"headers": {
								"type": "object",
								"additionalProperties": {
									"type": "string"
								},
								"description": "Custom HTTP headers to be sent with every request to this model's provider. These headers will be merged with the default headers (Authorization, Content-Type, User-Agent)."
							}
						},
						"required": [
							"id",
							"owned_by"
						]
					},
					"description": "A list of preferred models to use. If provided, these models will be used directly instead of fetching from the API."
				},
				"oaicopilot.retry": {
					"type": "object",
					"default": {
						"enabled": true,
						"max_attempts": 3,
						"interval_ms": 1000
					},
					"properties": {
						"enabled": {
							"type": "boolean",
							"default": true,
							"description": "Enable retry mechanism for api errors. Default is true."
						},
						"max_attempts": {
							"type": "number",
							"default": 3,
							"minimum": 1,
							"description": "Maximum number of retry attempts. Default is 3."
						},
						"interval_ms": {
							"type": "number",
							"default": 1000,
							"minimum": 1,
							"description": "Interval between retry attempts in milliseconds. Default is 1000 (1 seconds)."
						}
					},
					"description": "Retry configuration for handling api errors like [429, 500, 502, 503, 504]."
				},
				"oaicopilot.delay": {
					"type": "number",
					"default": 0,
					"minimum": 0,
					"description": "Fixed delay in milliseconds between consecutive requests. Default is 0 (no delay)."
				}
			}
		}
	},
	"main": "./out/extension.js",
	"scripts": {
		"vscode:prepublish": "npm run compile",
		"download-api": "dts dev && mv vscode.proposed.*.ts src",
		"download-vsc-api": "dts 1.106.2 && mv vscode.dts.ts src",
		"compile": "tsc -p ./",
		"lint": "eslint",
		"format": "prettier --write .",
		"watch": "tsc -watch -p ./",
		"test": "npm run compile && vscode-test",
		"build": "npx @vscode/vsce package -o extension.vsix"
	},
	"dependencies": {
		"axios": "^1.13.2",
		"socks-proxy-agent": "^8.0.5"
	},
	"devDependencies": {
		"@eslint/js": "^9.13.0",
		"@stylistic/eslint-plugin": "^2.9.0",
		"@types/mocha": "^10.0.6",
		"@types/node": "^22",
		"@types/vscode": "^1.104.0",
		"@vscode/dts": "^0.4.1",
		"@vscode/test-cli": "^0.0.11",
		"@vscode/test-electron": "^2.5.2",
		"eslint": "^9.13.0",
		"prettier": "^3.1.0",
		"typescript": "^5.9.2",
		"typescript-eslint": "^8.39.0"
	}
}
